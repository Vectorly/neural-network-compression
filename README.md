
# neural-network-compression
Neural Network Compression

# Objective

# Approached Methods
We have started with these papers[Deep Compression](https://arxiv.org/abs/1510.00149) [SqueezeNet](https://arxiv.org/abs/1602.07360).

# Papers
* squeezenet paper
* deep compression

## Experiment 
1. Cifar classification using pytroch squeezenet
2. MNIST using pytorch squeTezenet

# Abstract
Recent research on deep convolutional neural networks (CNNs) has focused pri-marily on improving accuracy.  For a given accuracy level, it is typically possi-ble to identify multiple CNN architectures that achieve that accuracy level.  With equivalent accuracy, smaller CNN architectures offer at least three advantages:
(1) Smaller CNNs require less communication across servers during distributed train-ing. 
(2) Smaller CNNs require less bandwidth to export a new model from thecloud to an autonomous car.
(3) Smaller CNNs are more feasible to deploy on FP-GAs and other hardware with limited memory.

## Deep Compressio on MNIST LeNet-5
https://github.com/mightydeveloper/Deep-Compression-PyTorch


